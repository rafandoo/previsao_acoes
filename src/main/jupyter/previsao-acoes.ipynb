{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Exploratória de Dados (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O arquivo b3_stocks_1994_2020.csv contém o dataset que iremos analizar, nele temos informações básicas relativas a todas as ações negociadas na bolsa de valores B3 no período de julho de 1994 a dezembro de 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, realizamos uma análise para entender melhor as características do conjunto de dados relacionado às ações da bolsa de valores. Utilizamos o ticker 'BBDC4' como exemplo, que é o identificador de uma ação na bolsa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T19:17:30.803919Z",
     "iopub.status.busy": "2020-11-21T19:17:30.803155Z",
     "iopub.status.idle": "2020-11-21T19:17:30.806952Z",
     "shell.execute_reply": "2020-11-21T19:17:30.806234Z"
    },
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1701954986728,
     "user": {
      "displayName": "Rafael Camargo",
      "userId": "12909751583574933299"
     },
     "user_tz": 180
    },
    "id": "T8cYMoPxa_To",
    "papermill": {
     "duration": 0.022946,
     "end_time": "2020-11-21T19:17:30.807104",
     "exception": false,
     "start_time": "2020-11-21T19:17:30.784158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T19:17:30.869708Z",
     "iopub.status.busy": "2020-11-21T19:17:30.868671Z",
     "iopub.status.idle": "2020-11-21T19:17:30.872135Z",
     "shell.execute_reply": "2020-11-21T19:17:30.871429Z"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1701955242269,
     "user": {
      "displayName": "Rafael Camargo",
      "userId": "12909751583574933299"
     },
     "user_tz": 180
    },
    "id": "sdxsb3gTa_Ts",
    "papermill": {
     "duration": 0.021898,
     "end_time": "2020-11-21T19:17:30.872257",
     "exception": false,
     "start_time": "2020-11-21T19:17:30.850359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ticker = 'ITUB4' # eh o identificador de uma ação na bolsa de valores, no caso este ticker pertence ao Banco Bradesco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDfTicker(df, ticker: str):\n",
    "    return df[df['ticker'] == ticker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T19:17:30.910708Z",
     "iopub.status.busy": "2020-11-21T19:17:30.909717Z",
     "iopub.status.idle": "2020-11-21T19:17:33.465985Z",
     "shell.execute_reply": "2020-11-21T19:17:33.466574Z"
    },
    "executionInfo": {
     "elapsed": 3738,
     "status": "ok",
     "timestamp": 1701955247638,
     "user": {
      "displayName": "Rafael Camargo",
      "userId": "12909751583574933299"
     },
     "user_tz": 180
    },
    "id": "0RAHaEU7a_Tt",
    "papermill": {
     "duration": 2.579642,
     "end_time": "2020-11-21T19:17:33.466718",
     "exception": false,
     "start_time": "2020-11-21T19:17:30.887076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/workspaces/previsao-acoes/src/main/python/data/b3_stocks_1994_2020.csv', low_memory=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>ticker</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>norm_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>885780</th>\n",
       "      <td>2009-05-20</td>\n",
       "      <td>ITUB4</td>\n",
       "      <td>29.50</td>\n",
       "      <td>30.03</td>\n",
       "      <td>30.84</td>\n",
       "      <td>29.50</td>\n",
       "      <td>291812233.0</td>\n",
       "      <td>-0.828598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886110</th>\n",
       "      <td>2009-05-21</td>\n",
       "      <td>ITUB4</td>\n",
       "      <td>29.61</td>\n",
       "      <td>29.99</td>\n",
       "      <td>30.15</td>\n",
       "      <td>29.41</td>\n",
       "      <td>143839395.0</td>\n",
       "      <td>-0.835665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886441</th>\n",
       "      <td>2009-05-22</td>\n",
       "      <td>ITUB4</td>\n",
       "      <td>30.40</td>\n",
       "      <td>30.38</td>\n",
       "      <td>30.59</td>\n",
       "      <td>29.42</td>\n",
       "      <td>153292069.0</td>\n",
       "      <td>-0.766758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886758</th>\n",
       "      <td>2009-05-25</td>\n",
       "      <td>ITUB4</td>\n",
       "      <td>30.35</td>\n",
       "      <td>30.40</td>\n",
       "      <td>30.67</td>\n",
       "      <td>29.93</td>\n",
       "      <td>51834816.0</td>\n",
       "      <td>-0.763225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887092</th>\n",
       "      <td>2009-05-26</td>\n",
       "      <td>ITUB4</td>\n",
       "      <td>30.15</td>\n",
       "      <td>31.55</td>\n",
       "      <td>31.79</td>\n",
       "      <td>29.90</td>\n",
       "      <td>295076559.0</td>\n",
       "      <td>-0.560037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          datetime ticker   open  close   high    low       volume  norm_close\n",
       "885780  2009-05-20  ITUB4  29.50  30.03  30.84  29.50  291812233.0   -0.828598\n",
       "886110  2009-05-21  ITUB4  29.61  29.99  30.15  29.41  143839395.0   -0.835665\n",
       "886441  2009-05-22  ITUB4  30.40  30.38  30.59  29.42  153292069.0   -0.766758\n",
       "886758  2009-05-25  ITUB4  30.35  30.40  30.67  29.93   51834816.0   -0.763225\n",
       "887092  2009-05-26  ITUB4  30.15  31.55  31.79  29.90  295076559.0   -0.560037"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dft = getDfTicker(df, ticker)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "dft['norm_close'] = scaler.fit_transform(dft[['close']])\n",
    "\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['norm_close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- datetime: Esta coluna representa o timestamp ou a data e hora em que as informações da ação foram registradas. Geralmente, é uma série temporal que permite analisar as variações ao longo do tempo.\n",
    "\n",
    "- ticker: O ticker é um código único atribuído a cada ativo financeiro negociado em uma bolsa de valores. Ele serve como uma abreviação para identificar uma ação específica. No contexto do seu conjunto de dados, ticker indica qual ação específica está sendo observada.\n",
    "\n",
    "- open: Este é o preço de abertura da ação no mercado financeiro. Refere-se ao valor pelo qual uma ação é negociada quando o mercado é aberto.\n",
    "\n",
    "- close: O preço de fechamento representa o valor pelo qual uma ação é negociada quando o mercado é fechado. É um indicador crucial para avaliar o desempenho de uma ação durante um período específico.\n",
    "\n",
    "- high: O preço mais alto (máximo) que a ação atingiu durante o período de tempo específico registrado na linha do dataset. Indica o ponto máximo de valor atingido pela ação durante o período.\n",
    "\n",
    "- low: O preço mais baixo (mínimo) que a ação atingiu durante o período de tempo registrado na linha do dataset. Indica o ponto mínimo de valor atingido pela ação durante o período.\n",
    "\n",
    "- volume: O volume de negociação é a quantidade total de ações que foram negociadas durante o período de tempo especificado. Representa a liquidez e a atividade do mercado para a ação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T19:17:33.842194Z",
     "iopub.status.busy": "2020-11-21T19:17:33.841384Z",
     "iopub.status.idle": "2020-11-21T19:17:33.854389Z",
     "shell.execute_reply": "2020-11-21T19:17:33.854961Z"
    },
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1701955251803,
     "user": {
      "displayName": "Rafael Camargo",
      "userId": "12909751583574933299"
     },
     "user_tz": 180
    },
    "id": "_fvw0sXMa_Tv",
    "papermill": {
     "duration": 0.373196,
     "end_time": "2020-11-21T19:17:33.855152",
     "exception": false,
     "start_time": "2020-11-21T19:17:33.481956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dft = getDfTicker(df, ticker)\n",
    "\n",
    "entrada = ['open', 'low', 'high', 'volume']\n",
    "saida = ['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "execution": {
     "iopub.execute_input": "2020-11-21T19:17:33.893679Z",
     "iopub.status.busy": "2020-11-21T19:17:33.892926Z",
     "iopub.status.idle": "2020-11-21T19:17:34.978864Z",
     "shell.execute_reply": "2020-11-21T19:17:34.979474Z"
    },
    "executionInfo": {
     "elapsed": 2671,
     "status": "ok",
     "timestamp": 1701955281736,
     "user": {
      "displayName": "Rafael Camargo",
      "userId": "12909751583574933299"
     },
     "user_tz": 180
    },
    "id": "ng8l1H7ca_Tv",
    "outputId": "04ac637b-a448-4146-b352-d6bbd74f6d58",
    "papermill": {
     "duration": 1.108535,
     "end_time": "2020-11-21T19:17:34.979636",
     "exception": false,
     "start_time": "2020-11-21T19:17:33.871101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.plot(dft['datetime'], dft['close'])\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(20))\n",
    "plt.title(f\"Série Temporal do Preço de Fechamento para {ticker}\")\n",
    "plt.xlabel(\"Data\")\n",
    "plt.ylabel(\"Preço de Fechamento\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição das Variáveis\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(15, 5))\n",
    "dft[entrada].hist(ax=axes, bins=20)\n",
    "axes[0].set_title(\"Distribuição das Variáveis de Entrada\")\n",
    "axes[1].hist(dft[saida].values, bins=20, color='skyblue', edgecolor='black')\n",
    "axes[1].set_title(\"Distribuição da Variável de Saída\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Esta função cria janelas temporais a partir de um DataFrame (df). Uma janela temporal consiste em uma sequência\n",
    "contínua de observações no DataFrame. size especifica o tamanho da janela, e ahead indica quantas observações à \n",
    "frente devem ser previstas. A função retorna duas listas, uma contendo as janelas de entrada (x) e outra contendo \n",
    "as saídas previstas (y)\n",
    "'''\n",
    "def createWindow(df, size, ahead):\n",
    "    x, y = [], []\n",
    "\n",
    "    for i in range(len(df) - size - ahead):\n",
    "        x.append(df.iloc[i:i + size])\n",
    "        y.append(df.iloc[i + size + ahead - 1])\n",
    "\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Normaliza as colunas especificadas (cols) dos DataFrames de entrada (dfX) e saída prevista (dfY). \n",
    "A normalização é feita em relação ao valor inicial, subtraindo 1 para representar as mudanças percentuais.\n",
    "'''\n",
    "def normCols(dfX, dfY, cols):\n",
    "    normX = dfX[cols] / dfX[cols].iloc[0] - 1\n",
    "    normY = dfY.to_frame().T[cols] / dfX[cols].iloc[0] - 1\n",
    "\n",
    "    return normX, normY\n",
    "\n",
    "'''\n",
    "Realiza a operação inversa à normalização, ou seja, desnormaliza os DataFrames normalizados (dfNormX e dfNormY).\n",
    "Retorna os DataFrames desnormalizados.\n",
    "'''\n",
    "def denormCols(dfX, dfNormX, dfNormY, cols):\n",
    "    dfDenormX = dfX[cols].iloc[0] * (dfNormX[cols] + 1)\n",
    "    dfDenormY = dfX[cols].iloc[0] * (dfNormY[cols] + 1)\n",
    "\n",
    "    return dfDenormX, dfDenormY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Essa função transforma as previsões normalizadas de um modelo de volta para a escala original \n",
    "dos dados, usando as informações contidas nas janelas temporais usadas para fazer as previsões. \n",
    "'''\n",
    "\n",
    "def denormPreds(xWindows, normPreds, col):\n",
    "    preds = np.zeros_like(normPreds)\n",
    "    for i, window in enumerate(xWindows):\n",
    "        preds[i] = window[col].iloc[0] * (normPreds[i] + 1)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Utiliza as funções anteriores para criar conjuntos de dados para treinamento de cnnos. \n",
    "Cria janelas temporais, normaliza as colunas de entrada e saída, e retorna arrays numpy \n",
    "prontos para treinamento. xCols é a lista de colunas de entrada e yCol é a coluna de \n",
    "saída a ser prevista.\n",
    "'''\n",
    "def createDataset(df, windowSize, ahead, xCols, yCol):\n",
    "    xWindows, yWindows = createWindow(df, windowSize, ahead)\n",
    "\n",
    "    xCols = xCols if isinstance(xCols, list) else [xCols]\n",
    "    xLst, yLst = [], []\n",
    "\n",
    "    for xWindow, yWindow in zip(xWindows, yWindows):\n",
    "\n",
    "        xNorm, yNorm = normCols(xWindow, yWindow, xCols)\n",
    "\n",
    "        xLst.append(xNorm.to_numpy())\n",
    "        yLst.append(yNorm[yCol].to_numpy().astype('float').squeeze())\n",
    "\n",
    "    return xWindows, yWindows, np.stack(xLst), np.stack(yLst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Divide os conjuntos de dados em conjuntos de treinamento e teste. percent determina a porcentagem dos \n",
    "dados a serem usados para treinamento, e o restante é usado para teste. Retorna uma tupla contendo\n",
    "os conjuntos de treinamento e teste.\n",
    "'''\n",
    "def splitTrainTest(items, percent=0.8):\n",
    "    results = []\n",
    "    for item in items:\n",
    "        split = int(len(item) * percent)\n",
    "        results.append(item[:split])\n",
    "        results.append(item[split:])\n",
    "\n",
    "    return tuple(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Long Short-Term Memory Networks, ou LSTMs, são uma variante especializada de redes neurais recorrentes (RNNs), projetadas para lidar com o problema do desaparecimento do gradiente, que é comum em RNNs tradicionais. As LSTMs foram propostas por Hochreiter & Schmidhuber em 1997 e têm sido amplamente utilizadas em tarefas relacionadas a sequências, como processamento de linguagem natural, reconhecimento de fala e séries temporais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estrutura Básica:\n",
    "\n",
    "- Uma LSTM é composta por células de memória, portões de entrada, portões de esquecimento e portões de saída.\n",
    "- Cada célula de memória mantém e atualiza uma \"memória de longo prazo\", permitindo a retenção de informações relevantes ao longo do tempo.\n",
    "\n",
    "Portões:\n",
    "\n",
    "- Os portões são componentes-chave das LSTMs e incluem o portão de entrada, o portão de esquecimento e o portão de saída.\n",
    "- Portão de Entrada (Input Gate): Regula quais informações da entrada devem ser armazenadas na célula de memória.\n",
    "- Portão de Esquecimento (Forget Gate): Decide quais informações antigas na célula de memória devem ser descartadas ou mantidas.\n",
    "- Portão de Saída (Output Gate): Determina a saída da célula de memória com base na entrada atual e na memória de longo prazo.\n",
    "\n",
    "Atualização da Célula de Memória:\n",
    "\n",
    "- O estado da célula de memória é atualizado multiplicando a saída do portão de esquecimento pela memória existente e somando a multiplicação da saída do portão de entrada pelos candidatos a valores de atualização.\n",
    "\n",
    "Backpropagation Through Time (BPTT):\n",
    "\n",
    "- LSTMs utilizam o algoritmo de retropropagação através do tempo para otimização.\n",
    "- O gradiente é passado ao longo da sequência temporal durante o treinamento, permitindo o aprendizado de dependências de longo prazo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2020-11-21T19:17:35.182680Z",
     "iopub.status.busy": "2020-11-21T19:17:35.146620Z",
     "iopub.status.idle": "2020-11-21T19:18:03.718857Z",
     "shell.execute_reply": "2020-11-21T19:18:03.718197Z"
    },
    "executionInfo": {
     "elapsed": 29880,
     "status": "ok",
     "timestamp": 1701955393243,
     "user": {
      "displayName": "Rafael Camargo",
      "userId": "12909751583574933299"
     },
     "user_tz": 180
    },
    "id": "-6ini94Ta_Ty",
    "outputId": "6fb37de7-8840-47cb-da22-15470732c016",
    "papermill": {
     "duration": 28.62503,
     "end_time": "2020-11-21T19:18:03.718987",
     "exception": false,
     "start_time": "2020-11-21T19:17:35.093957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "windowSize = 20\n",
    "predictAhead = 1\n",
    "\n",
    "xWindows, yWindows, xNorm, yNorm = createDataset(df=dft, windowSize=windowSize, ahead=predictAhead, xCols=entrada, yCol=saida)\n",
    "xNorm.shape, yNorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T19:18:03.764965Z",
     "iopub.status.busy": "2020-11-21T19:18:03.763937Z",
     "iopub.status.idle": "2020-11-21T19:18:03.767622Z",
     "shell.execute_reply": "2020-11-21T19:18:03.766864Z"
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1701955398466,
     "user": {
      "displayName": "Rafael Camargo",
      "userId": "12909751583574933299"
     },
     "user_tz": 180
    },
    "id": "A8vj_vEIa_Ty",
    "papermill": {
     "duration": 0.029293,
     "end_time": "2020-11-21T19:18:03.767757",
     "exception": false,
     "start_time": "2020-11-21T19:18:03.738464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split train and test packs\n",
    "xTrain, xTest, yTrain, yTest = splitTrainTest([xWindows, yWindows], percent=0.85)\n",
    "xNormTrain, xNormTest, yNormTrain, yNormTest = splitTrainTest([xNorm, yNorm], percent=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "lstm = keras.Sequential()\n",
    "\n",
    "# Adiciona uma camada LSTM com 50 neurónios\n",
    "lstm.add(LSTM(units=50, return_sequences=True, input_shape=(xNormTrain.shape[1], len(entrada))))\n",
    "# Adiciona uma camada de dropout para evitar overfitting\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(LSTM(units=50, return_sequences=True))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(LSTM(units=50))\n",
    "lstm.add(Dropout(0.2))\n",
    "# Camada de saida com 1 neuronio denso\n",
    "lstm.add(Dense(units=1))\n",
    "\n",
    "lstm.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T19:18:10.143982Z",
     "iopub.status.busy": "2020-11-21T19:18:10.142902Z",
     "iopub.status.idle": "2020-11-21T19:18:10.148548Z",
     "shell.execute_reply": "2020-11-21T19:18:10.147770Z"
    },
    "id": "kYi7ZolBa_T1",
    "papermill": {
     "duration": 0.031191,
     "end_time": "2020-11-21T19:18:10.148676",
     "exception": false,
     "start_time": "2020-11-21T19:18:10.117485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2020-11-21T19:18:10.195503Z",
     "iopub.status.busy": "2020-11-21T19:18:10.194711Z",
     "iopub.status.idle": "2020-11-21T19:18:37.051973Z",
     "shell.execute_reply": "2020-11-21T19:18:37.051215Z"
    },
    "executionInfo": {
     "elapsed": 78577,
     "status": "ok",
     "timestamp": 1701955622655,
     "user": {
      "displayName": "Rafael Camargo",
      "userId": "12909751583574933299"
     },
     "user_tz": 180
    },
    "id": "vUMHMF4ga_T2",
    "outputId": "21047ddc-c297-4684-dc92-24ef8e1a82ad",
    "papermill": {
     "duration": 26.883276,
     "end_time": "2020-11-21T19:18:37.052123",
     "exception": false,
     "start_time": "2020-11-21T19:18:10.168847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm.fit(\n",
    "    xNormTrain, \n",
    "    yNormTrain,\n",
    "    validation_data=(xNormTest, yNormTest),\n",
    "    batch_size=64,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão\n",
    "normPreds = lstm.predict(xNormTest)\n",
    "lstmPreds = denormPreds(xTest, normPreds, saida)\n",
    "lstmY = denormPreds(xTest, yNormTest, saida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXWxjniba_T5",
    "papermill": {
     "duration": 0.157054,
     "end_time": "2020-11-21T19:18:41.495867",
     "exception": false,
     "start_time": "2020-11-21T19:18:41.338813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(lstmY, color='orange', label=f\"Valor real - {ticker}\")\n",
    "plt.plot(lstmPreds[:,0], color='blue', label=f\"Valor previsto - {ticker}\")\n",
    "plt.xlabel(\"tempo\")\n",
    "plt.ylabel(f\"{ticker} preço\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Convolutional Neural Networks (CNNs) são uma classe de redes neurais profundas projetadas principalmente para tarefas de visão computacional, como classificação de imagem e detecção de objetos. No entanto, também podem ser adaptadas para tarefas de regressão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquitetura Básica:\n",
    "\n",
    "- As CNNs incluem camadas de convolução, pooling e camadas totalmente conectadas.\n",
    "- As camadas de convolução extraem características espaciais das entradas.\n",
    "- As camadas de pooling reduzem a dimensionalidade das características, preservando informações importantes.\n",
    "- As camadas totalmente conectadas processam as características extraídas e geram a saída final.\n",
    "\n",
    "Camadas de Convolução:\n",
    "\n",
    "- As camadas de convolução aplicam filtros a pequenas regiões da entrada, permitindo a detecção de padrões locais.\n",
    "- Os filtros aprendem características como bordas, texturas e padrões simples.\n",
    "\n",
    "Camadas de Pooling:\n",
    "\n",
    "- As camadas de pooling reduzem a resolução espacial da entrada, reduzindo a quantidade de parâmetros e computação.\n",
    "- O pooling máximo ou médio é comumente usado para preservar as características mais importantes.\n",
    "\n",
    "Camadas Totalmente Conectadas:\n",
    "\n",
    "- As camadas totalmente conectadas processam características globalmente e geram a saída final.\n",
    "- São comuns ao final da arquitetura da CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "cnn = keras.Sequential()\n",
    "\n",
    "# Adicione uma camada convolucional 1D com 32 filtros, kernel_size 3, função de ativação 'relu' e mesma borda\n",
    "cnn.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', input_shape=(xNormTrain.shape[1], len(entrada))))\n",
    "cnn.add(MaxPooling1D(pool_size=2))  # Adicione uma camada de pooling para redução de dimensionalidade\n",
    "\n",
    "# Adicione outra camada convolucional 1D com 64 filtros, kernel_size 3, função de ativação 'relu' e mesma borda\n",
    "cnn.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'))\n",
    "cnn.add(MaxPooling1D(pool_size=2))  # Mais uma camada de pooling\n",
    "\n",
    "# Adicione uma camada Flatten para converter os dados para um vetor 1D antes de alimentar a camada densa\n",
    "cnn.add(Flatten())\n",
    "\n",
    "# Adicione uma camada densa com 128 neurônios e função de ativação 'relu'\n",
    "cnn.add(Dense(units=128, activation='relu'))\n",
    "cnn.add(Dropout(0.5))  # Adicione uma camada de dropout para evitar overfitting\n",
    "\n",
    "# Camada de saída com 1 neurônio para uma tarefa de regressão (ou ajuste para classificação, conforme necessário)\n",
    "cnn.add(Dense(units=1))\n",
    "\n",
    "# Compile o modelo\n",
    "cnn.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Durante o treinamento, o callback ModelCheckpoint monitorará o desempenho do modelo na métrica\n",
    "de validação e salvará os pesos no arquivo especificado sempre que uma melhoria for observada. \n",
    "Isso é útil para reter apenas os melhores pesos do modelo, economizando recursos e facilitando \n",
    "a recuperação do melhor modelo treinado.\n",
    "'''\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='weights_best.hdf5', \n",
    "    verbose=2, \n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.fit(\n",
    "    xNormTrain, \n",
    "    yNormTrain, \n",
    "    validation_data=(xNormTest, yNormTest), \n",
    "    epochs=40,\n",
    "    batch_size=64,\n",
    "    callbacks=[checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normPreds = cnn.predict(xNormTest)\n",
    "cnnPreds = denormPreds(xTest, normPreds, saida)\n",
    "cnnY = denormPreds(xTest, yNormTest, saida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(cnnY, color='orange', label=f\"Actual {ticker} price\")\n",
    "plt.plot(cnnPreds[:,0], color='blue', label=f\"Predicted {ticker} price\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(f\"{ticker} price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Network (FNN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Feedforward Neural Network (Rede Neural de Avanço ou Rede Neural de Propagação Direta) é um tipo fundamental de arquitetura de rede neural, onde as informações fluem em uma única direção, da camada de entrada para a camada de saída, sem retroalimentação. Esta é a arquitetura mais simples e comum de uma rede neural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrada (Input Layer):\n",
    "\n",
    "- Camada Densa (Dense): A primeira camada densa possui 50 neurônios (ou unidades) e utiliza a função de ativação ReLU (Rectified Linear Unit). A entrada tem a forma (xNormTrain.shape[1], len(entrada)), o que sugere que ela aceita entradas relacionadas ao formato (número_de_janelas_temporais, número_de_características). A função de ativação ReLU ajuda a introduzir não linearidades na rede.\n",
    "\n",
    "- Dropout: Uma camada de Dropout com uma taxa de 0.2 é adicionada após cada camada densa para reduzir o overfitting. O Dropout desativa aleatoriamente um determinado número de neurônios durante o treinamento para evitar que a rede se torne excessivamente dependente de neurônios específicos.\n",
    "\n",
    "Camadas Intermediárias (Hidden Layers):\n",
    "\n",
    "- Duas camadas densas adicionais com 50 neurônios cada e funções de ativação ReLU seguidas por camadas Dropout. Cada camada densa introduz mais complexidade e capacidade de aprendizado à rede.\n",
    "\n",
    "Camada Flatten:\n",
    "\n",
    "- Camada Flatten: Esta camada transforma os dados de entrada em uma forma unidimensional (aplanada). Isso é necessário para conectar as camadas densas finais.\n",
    "\n",
    "Saída (Output Layer):\n",
    "\n",
    "- Camada Densa (Dense): A última camada densa possui 1 neurônio, que é a camada de saída para a tarefa de regressão. A função de ativação padrão é linear, o que é apropriado para problemas de regressão, pois produzirá uma saída contínua.\n",
    "\n",
    "Compilação:\n",
    "\n",
    "- A rede é compilada usando o otimizador 'adam' e a função de perda 'mean_squared_error'. O otimizador 'adam' é uma escolha comum para treinamento de redes neurais, e a função de perda MSE (Erro Quadrático Médio) é adequada para problemas de regressão, onde o objetivo é minimizar a diferença ao quadrado entre as previsões e os valores reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "fnn = Sequential()\n",
    "\n",
    "# Adicione camadas densas para incorporar características temporais atrasadas\n",
    "fnn.add(Dense(units=50, activation='relu', input_shape=(xNormTrain.shape[1], len(entrada))))\n",
    "fnn.add(Dropout(0.2))\n",
    "\n",
    "fnn.add(Dense(units=50, activation='relu'))\n",
    "fnn.add(Dropout(0.2))\n",
    "\n",
    "fnn.add(Dense(units=50, activation='relu'))\n",
    "fnn.add(Dropout(0.2))\n",
    "\n",
    "# Adicione camada Flatten para preparar para a camada densa final\n",
    "fnn.add(Flatten())\n",
    "\n",
    "# Adicione uma camada densa para a saída\n",
    "fnn.add(Dense(units=1))\n",
    "\n",
    "# Compile o modelo\n",
    "fnn.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnn.fit(\n",
    "    xNormTrain, \n",
    "    yNormTrain, \n",
    "    validation_data=(xNormTest, yNormTest), \n",
    "    epochs=20, \n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normPreds = fnn.predict(xNormTest)\n",
    "fnnPreds = denormPreds(xTest, normPreds, saida)\n",
    "fnnY = denormPreds(xTest, yNormTest, saida)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metricas de Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R² (R-squared):\n",
    "\n",
    "- O coeficiente de determinação, também conhecido como R², é uma medida estatística que indica a proporção da variância na variável dependente que é previsível a partir da(s) variável(eis) independente(s). O R² varia de 0 a 1, onde 1 indica um ajuste perfeito do modelo aos dados.\n",
    "\n",
    "R² Ajustado (Adjusted R-squared):\n",
    "\n",
    "- O R² ajustado leva em consideração o número de preditores no modelo. Ele penaliza a inclusão de variáveis irrelevantes que não contribuem significativamente para a explicação da variabilidade da variável dependente.\n",
    "\n",
    "MSE (Mean Squared Error):\n",
    "\n",
    "- O Erro Quadrático Médio é a média dos quadrados dos erros entre os valores previstos e os valores reais. Quanto menor o MSE, melhor o modelo está ajustado aos dados.\n",
    "\n",
    "RMSE (Root Mean Squared Error):\n",
    "\n",
    "- O RMSE é a raiz quadrada do MSE, e representa a média dos erros absolutos. Ele fornece uma interpretação mais intuitiva dos erros do modelo na mesma unidade da variável de resposta.\n",
    "\n",
    "MAPE (Mean Absolute Percentage Error):\n",
    "\n",
    "- O Erro Médio Percentual Absoluto é uma métrica expressa como uma porcentagem que mede a precisão do modelo em relação às previsões. O MAPE calcula a média das porcentagens absolutas de erro.\n",
    "\n",
    "MAE (Mean Absolute Error):\n",
    "\n",
    "- O Erro Absoluto Médio é a média dos valores absolutos das diferenças entre os valores previstos e os valores reais. Ele fornece uma medida da magnitude média dos erros.\n",
    "\n",
    "RMSLE (Root Mean Squared Logarithmic Error):\n",
    "\n",
    "- O RMSLE é semelhante ao RMSE, mas é aplicado ao logaritmo dos valores previstos e reais. É útil quando as diferenças relativas são mais importantes do que as diferenças absolutas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score \n",
    "\n",
    "print(f\"R2 para LSTM: {r2_score(lstmY, lstmPreds[:, 0]):.5f}\")\n",
    "print(f\"R2 para CNN: {r2_score(cnnY, cnnPreds[:, 0]):.5f}\")\n",
    "print(f\"R2 para FNN: {r2_score(fnnY, fnnPreds[:, 0]):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustedR2(yTrue, yPred, n):\n",
    "    r2 = r2_score(yTrue, yPred)\n",
    "    return 1 - (1 - r2) * (n - 1) / (n - 2)\n",
    "\n",
    "print(f\"Adjusted R2 para LSTM: {adjustedR2(lstmY, lstmPreds[:, 0], len(lstmY)):.5f}\")\n",
    "print(f\"Adjusted R2 para CNN: {adjustedR2(cnnY, cnnPreds[:, 0], len(cnnY)):.5f}\")\n",
    "print(f\"Adjusted R2 para FNN: {adjustedR2(fnnY, fnnPreds[:, 0], len(fnnY)):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(f\"MSE para LSTM: {mean_squared_error(lstmY, lstmPreds[:, 0]):.5f}\")\n",
    "print(f\"MSE para CNN: {mean_squared_error(cnnY, cnnPreds[:, 0]):.5f}\")\n",
    "print(f\"MSE para FNN: {mean_squared_error(fnnY, fnnPreds[:, 0]):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE para LSTM: {np.sqrt(mean_squared_error(lstmY, lstmPreds[:, 0])):.5f}\")\n",
    "print(f\"RMSE para CNN: {np.sqrt(mean_squared_error(cnnY, cnnPreds[:, 0])):.5f}\")\n",
    "print(f\"RMSE para FNN: {np.sqrt(mean_squared_error(fnnY, fnnPreds[:, 0])):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(yTrue, yPred):\n",
    "    return np.mean(np.abs((yTrue - yPred) / yTrue)) * 100\n",
    "\n",
    "print(f\"MAPE para LSTM: {mape(lstmY, lstmPreds[:, 0]):.5f}%\")\n",
    "print(f\"MAPE para CNN: {mape(cnnY, cnnPreds[:, 0]):.5f}%\")\n",
    "print(f\"MAPE para FNN: {mape(fnnY, fnnPreds[:, 0]):.5f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(f\"MAE para LSTM: {mean_absolute_error(lstmY, lstmPreds[:, 0]):.5f}\")\n",
    "print(f\"MAE para CNN: {mean_absolute_error(cnnY, cnnPreds[:, 0]):.5f}\")\n",
    "print(f\"MAE para FNN: {mean_absolute_error(fnnY, fnnPreds[:, 0]):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "print(f\"RMSLE para LSTM: {np.sqrt(mean_squared_log_error(lstmY, lstmPreds[:, 0])):.5f}\")\n",
    "print(f\"RMSLE para CNN: {np.sqrt(mean_squared_log_error(cnnY, cnnPreds[:, 0])):.5f}\")\n",
    "print(f\"RMSLE para FNN: {np.sqrt(mean_squared_log_error(fnnY, fnnPreds[:, 0])):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nos resultados obtidos para os modelos LSTM (Long Short-Term Memory), CNN (Convolutional Neural Network) e FNN (Feedforward Neural Network), podemos fazer as seguintes interpretações:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos os modelos apresentam altos valores de R² e R² ajustado, indicando que eles são capazes de explicar uma porção significativa da variabilidade nos dados. O modelo LSTM obteve o melhor desempenho, seguido pelo CNN e FNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O RMSLE leva em consideração as diferenças relativas entre os valores previstos e reais em uma escala logarítmica. Todos os modelos apresentam valores baixos, com o LSTM e o CNN destacando-se em termos de precisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando todas as métricas avaliadas, o modelo LSTM demonstrou ser o mais eficaz na previsão dos preços da ação. Ele apresentou um desempenho superior ao CNN e FNN em todas as métricas analisadas. \n",
    "\n",
    "O CNN também teve um desempenho sólido, enquanto o FNN ficou um pouco atrás em termos de precisão, conforme indicado pelas métricas de avaliação. Esses resultados sugerem que modelos baseados em redes neurais recorrentes, como o LSTM, são promissores para tarefas de previsão em séries temporais financeiras. \n",
    "\n",
    "Importante destacar que o CNN não foi projetado para tarefas de previsão de séries temporais, mas sim para tarefas de classificação de imagens. Portanto, o fato de ter obtido um desempenho comparável ao LSTM é bastante impressionante."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "papermill": {
   "duration": 75.861587,
   "end_time": "2020-11-21T19:18:41.762018",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-21T19:17:25.900431",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
